task_name: train
tags:
- dev
train: true
test: true
ckpt_path: null
seed: null
log_vertexai: false
data:
  train_dataloader_config:
    dataset_config:
      _target_: src.data.components.interfaces.DatasetConfig
      user_id_field: userId
      min_sequence_length: 10
      iterate_per_row: true
      features_to_consider:
      - sequence_data
      - sequence_event_type
      num_placeholder_tokens_map:
        sequence_data: 100
      data_iterator:
        _target_: src.data.components.iterators.TFRecordIterator
      preprocessing_functions:
      - _target_: src.data.components.pre_processing.convert_to_dense_numpy_array
        _partial_: true
      - _target_: src.data.components.pre_processing.convert_fields_to_tensors
        _partial_: true
      - _target_: src.data.components.pre_processing.remove_oov_tokens
        _partial_: true
        oov_token: -1
      - _target_: src.data.components.pre_processing.filter_sequence_length_row
        _partial_: true
      - _target_: src.data.components.pre_processing.add_placeholder_tokens
        _partial_: true
    _target_: src.data.components.interfaces.DataloaderConfig
    dataset_class:
      _target_: src.data.components.dataloading.MultiSequenceIterable
      _partial_: true
    data_folder: ${paths.data_dir}/training
    should_shuffle_rows: true
    labels:
      sequence_data:
        transform:
          _target_: src.data.components.label_function.RandomMasking
          masking_probability: 0.15
    batch_size_per_device: 16
    num_workers: 4
    assign_files_by_size: false
    oov_token: -1
    masking_token: 1
    sequence_length: 800
    padding_token: 0
    drop_last: true
    pin_memory: true
    persistent_workers: true
    collate_fn:
      _target_: src.data.components.collate_functions.collate_fn_train
      _partial_: true
  val_dataloader_config:
    dataset_config:
      _target_: src.data.components.interfaces.DatasetConfig
      user_id_field: userId
      min_sequence_length: 10
      iterate_per_row: true
      features_to_consider:
      - sequence_data
      - sequence_event_type
      num_placeholder_tokens_map:
        sequence_data: 100
      data_iterator:
        _target_: src.data.components.iterators.TFRecordIterator
      preprocessing_functions:
      - _target_: src.data.components.pre_processing.convert_to_dense_numpy_array
        _partial_: true
      - _target_: src.data.components.pre_processing.convert_fields_to_tensors
        _partial_: true
      - _target_: src.data.components.pre_processing.remove_oov_tokens
        _partial_: true
        oov_token: -1
      - _target_: src.data.components.pre_processing.filter_sequence_length_row
        _partial_: true
      - _target_: src.data.components.pre_processing.add_placeholder_tokens
        _partial_: true
    _target_: src.data.components.interfaces.DataloaderConfig
    dataset_class:
      _target_: src.data.components.dataloading.MultiSequenceIterable
      _partial_: true
      for_train: false
    data_folder: ${paths.data_dir}/evaluation
    should_shuffle_rows: false
    labels:
      sequence_data:
        transform:
          _target_: src.data.components.label_function.NextTokenMasking
    batch_size_per_device: 16
    num_workers: 4
    assign_files_by_size: true
    oov_token: -1
    masking_token: 1
    sequence_length: 800
    padding_token: 0
    drop_last: true
    pin_memory: true
    persistent_workers: true
    collate_fn:
      _target_: src.data.components.collate_functions.collate_fn_train
      _partial_: true
  test_dataloader_config:
    dataset_config:
      _target_: src.data.components.interfaces.DatasetConfig
      user_id_field: userId
      min_sequence_length: 10
      iterate_per_row: true
      features_to_consider:
      - sequence_data
      - sequence_event_type
      num_placeholder_tokens_map:
        sequence_data: 100
      data_iterator:
        _target_: src.data.components.iterators.TFRecordIterator
      preprocessing_functions:
      - _target_: src.data.components.pre_processing.convert_to_dense_numpy_array
        _partial_: true
      - _target_: src.data.components.pre_processing.convert_fields_to_tensors
        _partial_: true
      - _target_: src.data.components.pre_processing.remove_oov_tokens
        _partial_: true
        oov_token: -1
      - _target_: src.data.components.pre_processing.filter_sequence_length_row
        _partial_: true
      - _target_: src.data.components.pre_processing.add_placeholder_tokens
        _partial_: true
    _target_: src.data.components.interfaces.DataloaderConfig
    dataset_class:
      _target_: src.data.components.dataloading.MultiSequenceIterable
      _partial_: true
      for_train: false
    data_folder: ${paths.data_dir}/testing
    should_shuffle_rows: false
    labels:
      sequence_data:
        transform:
          _target_: src.data.components.label_function.NextTokenMasking
    batch_size_per_device: 16
    num_workers: 4
    assign_files_by_size: true
    oov_token: -1
    masking_token: 1
    sequence_length: 800
    padding_token: 0
    drop_last: true
    pin_memory: true
    persistent_workers: true
    collate_fn:
      _target_: src.data.components.collate_functions.collate_fn_train
      _partial_: true
  _target_: src.data.sequence_datamodule.SequenceDataModule
model:
  huggingface_model:
    _target_: transformers.T5EncoderModel
    config:
      _target_: transformers.T5Config
      vocab_size: 1000100
      d_model: 32
      num_heads: 4
      dropout_rate: 0.15
      d_ff: 32
      d_kv: 32
      num_layers: 6
  _target_: src.models.modules.hf_transformer_module.HFTransformerModule
  feature_to_model_input_map:
    sequence_data: input_ids
    sequence_event_type: domain_ids
  postprocessor:
    _target_: src.models.components.network_blocks.mlp.MLP
    embedding_dim: 32
    d_dim: 32
    n_layers: 2
    activation:
      _target_: torch.nn.ReLU
      _partial_: true
  aggregator:
    _target_: src.models.components.network_blocks.embedding_aggregator.EmbeddingAggregator
    aggregation_strategy:
      _target_: src.models.components.network_blocks.aggregation_strategy.LastAggregation
  loss_function: ${loss.loss_function}
  optimizer: ${optim.optimizer}
  scheduler: ${optim.scheduler}
  evaluator: ${eval.evaluator}
  weight_tying: true
  compile: false
callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: checkpoint_{epoch:03d}_{step:06d}
    monitor: val/lowest_loss
    verbose: false
    save_last: null
    save_top_k: 1
    mode: min
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: 2000
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val/lowest_loss
    min_delta: 0.0
    patience: 100
    verbose: false
    mode: min
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: null
  model_summary:
    _target_: lightning.pytorch.callbacks.RichModelSummary
    max_depth: -1
logger:
  wandb:
    _target_: lightning.pytorch.loggers.wandb.WandbLogger
    save_dir: ${paths.output_dir}
    offline: false
    id: null
    anonymous: null
    log_model: false
    prefix: ''
    tags: []
    job_type: ''
trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  min_steps: 1
  max_steps: 200000
  max_epochs: 10
  accelerator: gpu
  devices: -1
  precision: 16-mixed
  log_every_n_steps: 1
  val_check_interval: 1000
  deterministic: false
  accumulate_grad_batches: 1
  num_nodes: 1
  sync_batchnorm: true
paths:
  root_dir: .
  data_dir: data
  log_dir: ${paths.root_dir}/logs
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
extras:
  ignore_warnings: false
  enforce_tags: true
  print_config: true
loss:
  loss_function:
    _target_: src.components.loss_functions.InBatchContrastiveLoss
    contrastive_tau: 0.1
    normalize: true
optim:
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.0001
    weight_decay: 1.0e-05
  scheduler:
    _target_: src.components.scheduler.WarmupLinearScheduler
    _partial_: true
    warmup_steps: 1000
    min_ratio: 0.3
    scheduler_steps: ${trainer.max_steps}
eval:
  evaluator:
    _target_: src.components.eval_metrics.Evaluator
    metrics:
      ndcg:
        _target_: src.components.eval_metrics.NDCG
        _partial_: true
      recall:
        _target_: src.components.eval_metrics.Recall
        _partial_: true
    top_k_list:
    - 20
    - 10
    should_sample_negatives_from_vocab: true
    num_negatives: 100
    placeholder_token_buffer: 100
